{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11897519,"sourceType":"datasetVersion","datasetId":7478775}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom transformers import DistilBertTokenizer, DistilBertModel\nimport os\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define your labels (make sure this matches training order)\ntarget_list = [\n    'BATTERY', 'PERFORMANCE', 'CAMERA', 'DISPLAY',\n    'PRICE', 'MULTIMEDIA', 'FITNESS & HEALTH TRACKING', 'CUSTOMIZATION'\n]\n\n\n\n# Constants\nMAX_LEN = 128\nMODEL_PATH = \"/kaggle/input/aspects-m/Aspect_Distilbert.bin\"  # Adjust if model is saved elsewhere\n\n# Tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\n# Model class definition\nclass DistilBERTClass(torch.nn.Module):\n    def __init__(self):\n        super(DistilBERTClass, self).__init__()\n        self.distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased', return_dict=True)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.linear = torch.nn.Linear(768, len(target_list))\n\n    def forward(self, input_ids, attention_mask):\n        output = self.distilbert_model(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = self.dropout(output.last_hidden_state[:, 0, :])\n        return self.linear(pooled_output)\n\n# Load the trained model\nmodel = DistilBERTClass()\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=device))\nmodel.to(device)\nmodel.eval()\n\n\n\n# Inference function\ndef infer(text):\n    encoded = tokenizer.encode_plus(\n        text,\n        max_length=MAX_LEN,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n\n    input_ids = encoded['input_ids'].to(device)\n    attention_mask = encoded['attention_mask'].to(device)\n\n    with torch.no_grad():\n        logits = model(input_ids, attention_mask)\n        probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n\n    binary_preds = (probs >= 0.5).astype(int)\n    return probs, binary_preds\n\n# Example usage\nraw_text = \"The camera is really disappointing and the display looks washed out. It also lags a lot when switching apps. I regret buying this.\"\n\nprobs, preds = infer(raw_text)\n\n# Output\nprint(f\"\\nInput: {raw_text}\\n\")\nprint(\"Detected Aspects and Probabilities:\")\nfor i, p in enumerate(preds):\n    if p == 1:\n        print(f\"‚úì {target_list[i]}: {probs[i]*100:.2f}%\")\n\nprint(\"\\nFull Aspect Probabilities:\")\nfor aspect, prob in sorted(zip(target_list, probs), key=lambda x: x[1], reverse=True):\n    print(f\"{aspect}: {prob*100:.2f}%\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:25:46.273006Z","iopub.execute_input":"2025-05-22T02:25:46.273285Z","iopub.status.idle":"2025-05-22T02:25:52.156801Z","shell.execute_reply.started":"2025-05-22T02:25:46.273265Z","shell.execute_reply":"2025-05-22T02:25:52.156156Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"011db446545642fba74bf945957bc90d"}},"metadata":{}},{"name":"stdout","text":"\nInput: The camera is really disappointing and the display looks washed out. It also lags a lot when switching apps. I regret buying this.\n\nDetected Aspects and Probabilities:\n‚úì PERFORMANCE: 60.44%\n‚úì CAMERA: 89.74%\n‚úì DISPLAY: 82.78%\n\nFull Aspect Probabilities:\nCAMERA: 89.74%\nDISPLAY: 82.78%\nPERFORMANCE: 60.44%\nBATTERY: 20.86%\nPRICE: 4.14%\nMULTIMEDIA: 1.08%\nCUSTOMIZATION: 0.90%\nFITNESS & HEALTH TRACKING: 0.82%\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\n\n#BERT\n\nfrom transformers import BertTokenizer, BertModel # Assuming BERT is intended\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\nfrom transformers import BertModel, BertTokenizer\n\n# Use BERT instead of DistilBERT\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\nclass BERTClass(torch.nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.linear = torch.nn.Linear(768, 8)\n\n    def forward(self, input_ids, attn_mask):\n        output = self.bert_model(input_ids, attention_mask=attn_mask)\n        output_dropout = self.dropout(output.last_hidden_state[:, 0, :])  # Use [CLS] token embedding\n        output = self.linear(output_dropout)\n        return output\n\n# Initialize the model\nmodel = BERTClass()\nmodel.to(device)\n\n\nMODEL_PATH = \"/kaggle/input/aspects-m/Aspect_BERT.bin\"  # Adjust if model is saved elsewhere\n\nmodel = BERTClass()  # Assuming you used BERT in the training\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=device))\nmodel.to(device)\nmodel.eval()\n\n\n# Inference function\ndef infer(text):\n    encoded = tokenizer.encode_plus(\n        text,\n        max_length=MAX_LEN,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n\n    input_ids = encoded['input_ids'].to(device)\n    attention_mask = encoded['attention_mask'].to(device)\n\n    with torch.no_grad():\n        logits = model(input_ids, attention_mask)\n        probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n\n    binary_preds = (probs >= 0.5).astype(int)\n    return probs, binary_preds\n\n# Example usage\nraw_text = \"The camera is really disappointing and the display looks washed out. It also lags a lot when switching apps. I regret buying this.\"\n\nprobs, preds = infer(raw_text)\n\n# Output\nprint(f\"\\nInput: {raw_text}\\n\")\nprint(\"Detected Aspects and Probabilities:\")\nfor i, p in enumerate(preds):\n    if p == 1:\n        print(f\"‚úì {target_list[i]}: {probs[i]*100:.2f}%\")\n\nprint(\"\\nFull Aspect Probabilities:\")\nfor aspect, prob in sorted(zip(target_list, probs), key=lambda x: x[1], reverse=True):\n    print(f\"{aspect}: {prob*100:.2f}%\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:26:19.958294Z","iopub.execute_input":"2025-05-22T02:26:19.958852Z","iopub.status.idle":"2025-05-22T02:26:28.993895Z","shell.execute_reply.started":"2025-05-22T02:26:19.958828Z","shell.execute_reply":"2025-05-22T02:26:28.993263Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a70ac16f76d3415eb40344692eaa1bba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"009478967f3d47f484bd33410d7f6447"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bce0260cefca4297b6754e5f4af078c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98680a8a6cd147b3bce6fde1d402a8b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e660d7560ac45d1b32e644943e0bf03"}},"metadata":{}},{"name":"stdout","text":"\nInput: The camera is really disappointing and the display looks washed out. It also lags a lot when switching apps. I regret buying this.\n\nDetected Aspects and Probabilities:\n‚úì PERFORMANCE: 95.57%\n‚úì CAMERA: 92.99%\n‚úì DISPLAY: 84.41%\n\nFull Aspect Probabilities:\nPERFORMANCE: 95.57%\nCAMERA: 92.99%\nDISPLAY: 84.41%\nBATTERY: 5.02%\nPRICE: 3.66%\nCUSTOMIZATION: 3.17%\nMULTIMEDIA: 1.48%\nFITNESS & HEALTH TRACKING: 0.66%\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\n\n#RoBERTa\n\nfrom transformers import RobertaTokenizer, RobertaModel\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\n# Test the tokenizer\ntest_text = \"We are testing BERT tokenizer.\"\n# generate encodings\nencodings = tokenizer.encode_plus(test_text,\n                                  add_special_tokens = True,\n                                  max_length = 50,\n                                  truncation = True,\n                                  padding = \"max_length\",\n                                  return_attention_mask = True,\n                                  return_tensors = \"pt\")\n# we get a dictionary with three keys (see: https://huggingface.co/transformers/glossary.html)\nencodings\n\nclass RoBERTaClass(torch.nn.Module):\n    def __init__(self):\n        super(RoBERTaClass, self).__init__()\n        self.roberta_model = RobertaModel.from_pretrained('roberta-base', return_dict=True)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.linear = torch.nn.Linear(768, 8)\n\n    def forward(self, input_ids, attn_mask):\n        output = self.roberta_model(\n            input_ids,\n            attention_mask=attn_mask\n        )\n        output_dropout = self.dropout(output.pooler_output)\n        output = self.linear(output_dropout)\n        return output\n\nmodel = RoBERTaClass()\nmodel.to(device)\n\n# Loading pretrained model (best model)\nMODEL_PATH = \"/kaggle/input/aspects-m/Aspect_roberta.bin\"  # Adjust if model is saved elsewhere\n\nmodel = RoBERTaClass()\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=device))\nmodel.to(device)\nmodel.eval()\n\n# Inference function\ndef infer(text):\n    encoded = tokenizer.encode_plus(\n        text,\n        max_length=MAX_LEN,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n\n    input_ids = encoded['input_ids'].to(device)\n    attention_mask = encoded['attention_mask'].to(device)\n\n    with torch.no_grad():\n        logits = model(input_ids, attention_mask)\n        probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n\n    binary_preds = (probs >= 0.5).astype(int)\n    return probs, binary_preds\n\n# Example usage\nraw_text = \"The camera is really disappointing and the display looks washed out. It also lags a lot when switching apps. I regret buying this.\"\n\nprobs, preds = infer(raw_text)\n\n# Output\nprint(f\"\\nInput: {raw_text}\\n\")\nprint(\"Detected Aspects and Probabilities:\")\nfor i, p in enumerate(preds):\n    if p == 1:\n        print(f\"‚úì {target_list[i]}: {probs[i]*100:.2f}%\")\n\nprint(\"\\nFull Aspect Probabilities:\")\nfor aspect, prob in sorted(zip(target_list, probs), key=lambda x: x[1], reverse=True):\n    print(f\"{aspect}: {prob*100:.2f}%\")\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:26:55.824926Z","iopub.execute_input":"2025-05-22T02:26:55.825634Z","iopub.status.idle":"2025-05-22T02:27:06.807986Z","shell.execute_reply.started":"2025-05-22T02:26:55.825607Z","shell.execute_reply":"2025-05-22T02:27:06.807025Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0a7fa0ead6742e2ad810f1ac6d771ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8210f505dcc144f9a123211c294d75ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"398a8b7a0d0d4c019f57272f0f3def81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c024a6e5ac00459f8605143dc84a4c0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c746c0fa8c8f466a8d2fae3e35096acb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cf929bca3244b11b9764bda0db02894"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nInput: The camera is really disappointing and the display looks washed out. It also lags a lot when switching apps. I regret buying this.\n\nDetected Aspects and Probabilities:\n‚úì PERFORMANCE: 64.41%\n‚úì CAMERA: 91.59%\n‚úì DISPLAY: 95.97%\n\nFull Aspect Probabilities:\nDISPLAY: 95.97%\nCAMERA: 91.59%\nPERFORMANCE: 64.41%\nBATTERY: 4.02%\nFITNESS & HEALTH TRACKING: 3.44%\nMULTIMEDIA: 3.42%\nPRICE: 3.04%\nCUSTOMIZATION: 2.03%\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom transformers import DistilBertTokenizer, BertTokenizer, RobertaTokenizer\n\n# Your input text\ntext = \"The camera is really disappointing and the display looks washed out. It also lags a lot when switching apps. I regret buying this.\"\n\n# ‚îÄ‚îÄ‚îÄ 1) DistilBERT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\ndistil_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\ndistil_model = DistilBERTClass()\ndistil_model.load_state_dict(torch.load(\"/kaggle/input/aspects-m/Aspect_Distilbert.bin\", map_location=device))\ndistil_model.to(device).eval()\n\ndef infer_distilbert(text):\n    enc = distil_tokenizer.encode_plus(\n        text,\n        max_length=MAX_LEN,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n    ids, mask = enc['input_ids'].to(device), enc['attention_mask'].to(device)\n    with torch.no_grad():\n        logits = distil_model(ids, mask)\n    probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n    return probs, (probs >= 0.5).astype(int)\n\n# ‚îÄ‚îÄ‚îÄ 2) BERT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = BERTClass()\nbert_model.load_state_dict(torch.load(\"/kaggle/input/aspects-m/Aspect_BERT.bin\", map_location=device))\nbert_model.to(device).eval()\n\ndef infer_bert(text):\n    enc = bert_tokenizer.encode_plus(\n        text,\n        max_length=MAX_LEN,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n    ids, mask = enc['input_ids'].to(device), enc['attention_mask'].to(device)\n    with torch.no_grad():\n        logits = bert_model(ids, mask)\n    probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n    return probs, (probs >= 0.5).astype(int)\n\n# ‚îÄ‚îÄ‚îÄ 3) RoBERTa ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nroberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nroberta_model = RoBERTaClass()\nroberta_model.load_state_dict(torch.load(\"/kaggle/input/aspects-m/Aspect_roberta.bin\", map_location=device))\nroberta_model.to(device).eval()\n\ndef infer_roberta(text):\n    enc = roberta_tokenizer.encode_plus(\n        text,\n        max_length=MAX_LEN,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n    ids, mask = enc['input_ids'].to(device), enc['attention_mask'].to(device)\n    with torch.no_grad():\n        logits = roberta_model(ids, mask)\n    probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n    return probs, (probs >= 0.5).astype(int)\n\n# ‚îÄ‚îÄ‚îÄ 4) Run & Combine ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\ndb_probs, db_preds = infer_distilbert(text)\nb_probs,  b_preds  = infer_bert(text)\nr_probs,  r_preds  = infer_roberta(text)\n\ndf = pd.DataFrame({\n    'DistilBERT_prob': db_probs,\n    'DistilBERT_pred': db_preds,\n    'BERT_prob':       b_probs,\n    'BERT_pred':       b_preds,\n    'RoBERTa_prob':    r_probs,\n    'RoBERTa_pred':    r_preds,\n}, index=target_list)\n\nprint(df)\nprint(\"\\nDetected Aspects by Model:\")\nfor name, (probs, preds) in {\n    \"DistilBERT\": (db_probs, db_preds),\n    \"BERT\":       (b_probs,  b_preds),\n    \"RoBERTa\":    (r_probs,  r_preds),\n}.items():\n    detected = [f\"{asp} ({probs[i]*100:.1f}%)\" \n                for i, (asp, p) in enumerate(zip(target_list, preds)) if p]\n    print(f\"  {name}: {', '.join(detected) if detected else 'None'}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:32:54.620679Z","iopub.execute_input":"2025-05-22T02:32:54.621360Z","iopub.status.idle":"2025-05-22T02:32:58.954533Z","shell.execute_reply.started":"2025-05-22T02:32:54.621338Z","shell.execute_reply":"2025-05-22T02:32:58.953917Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"                           DistilBERT_prob  DistilBERT_pred  BERT_prob  \\\nBATTERY                           0.208596                0   0.050227   \nPERFORMANCE                       0.604361                1   0.955733   \nCAMERA                            0.897433                1   0.929858   \nDISPLAY                           0.827839                1   0.844125   \nPRICE                             0.041445                0   0.036614   \nMULTIMEDIA                        0.010825                0   0.014841   \nFITNESS & HEALTH TRACKING         0.008192                0   0.006648   \nCUSTOMIZATION                     0.008984                0   0.031664   \n\n                           BERT_pred  RoBERTa_prob  RoBERTa_pred  \nBATTERY                            0      0.040204             0  \nPERFORMANCE                        1      0.644053             1  \nCAMERA                             1      0.915866             1  \nDISPLAY                            1      0.959731             1  \nPRICE                              0      0.030396             0  \nMULTIMEDIA                         0      0.034224             0  \nFITNESS & HEALTH TRACKING          0      0.034389             0  \nCUSTOMIZATION                      0      0.020280             0  \n\nDetected Aspects by Model:\n  DistilBERT: PERFORMANCE (60.4%), CAMERA (89.7%), DISPLAY (82.8%)\n  BERT: PERFORMANCE (95.6%), CAMERA (93.0%), DISPLAY (84.4%)\n  RoBERTa: PERFORMANCE (64.4%), CAMERA (91.6%), DISPLAY (96.0%)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom transformers import (\n    DistilBertTokenizer, DistilBertModel,\n    BertTokenizer, BertModel,\n    RobertaTokenizer, RobertaModel\n)\nimport os\nimport logging\nfrom typing import Dict, List, Tuple, Optional\nimport warnings\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlogger.info(f\"Using device: {device}\")\n\n# Define your labels\ntarget_list = [\n    'BATTERY', 'PERFORMANCE', 'CAMERA', 'DISPLAY',\n    'PRICE', 'MULTIMEDIA', 'FITNESS & HEALTH TRACKING', 'CUSTOMIZATION'\n]\n\n# Constants\nMAX_LEN = 128\nMODEL_PATHS = {\n    'distilbert': \"/kaggle/input/aspects-m/Aspect_Distilbert.bin\",\n    'bert': \"/kaggle/input/aspects-m/Aspect_BERT.bin\", \n    'roberta': \"/kaggle/input/aspects-m/Aspect_roberta.bin\"\n}\n\n# Model Classes\nclass DistilBERTClass(torch.nn.Module):\n    def __init__(self):\n        super(DistilBERTClass, self).__init__()\n        self.distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased', return_dict=True)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.linear = torch.nn.Linear(768, len(target_list))\n\n    def forward(self, input_ids, attention_mask):\n        output = self.distilbert_model(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = self.dropout(output.last_hidden_state[:, 0, :])\n        return self.linear(pooled_output)\n\nclass BERTClass(torch.nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.linear = torch.nn.Linear(768, 8)\n\n    def forward(self, input_ids, attn_mask):\n        output = self.bert_model(input_ids, attention_mask=attn_mask)\n        output_dropout = self.dropout(output.last_hidden_state[:, 0, :])\n        output = self.linear(output_dropout)\n        return output\n\nclass RoBERTaClass(torch.nn.Module):\n    def __init__(self):\n        super(RoBERTaClass, self).__init__()\n        self.roberta_model = RobertaModel.from_pretrained('roberta-base', return_dict=True)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.linear = torch.nn.Linear(768, 8)\n\n    def forward(self, input_ids, attn_mask):\n        output = self.roberta_model(input_ids, attention_mask=attn_mask)\n        output_dropout = self.dropout(output.pooler_output)\n        output = self.linear(output_dropout)\n        return output\n\nclass AspectEnsemble:\n    def __init__(self):\n        self.models = {}\n        self.tokenizers = {}\n        self.model_status = {}\n        self._initialize_models()\n    \n    def _initialize_models(self):\n        \"\"\"Initialize all models with error handling\"\"\"\n        \n        # DistilBERT\n        try:\n            if os.path.exists(MODEL_PATHS['distilbert']):\n                self.tokenizers['distilbert'] = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n                self.models['distilbert'] = DistilBERTClass()\n                self.models['distilbert'].load_state_dict(torch.load(MODEL_PATHS['distilbert'], map_location=device))\n                self.models['distilbert'].to(device)\n                self.models['distilbert'].eval()\n                self.model_status['distilbert'] = True\n                logger.info(\"‚úì DistilBERT model loaded successfully\")\n            else:\n                logger.warning(f\"‚úó DistilBERT model file not found: {MODEL_PATHS['distilbert']}\")\n                self.model_status['distilbert'] = False\n        except Exception as e:\n            logger.error(f\"‚úó Failed to load DistilBERT model: {str(e)}\")\n            self.model_status['distilbert'] = False\n        \n        # BERT\n        try:\n            if os.path.exists(MODEL_PATHS['bert']):\n                self.tokenizers['bert'] = BertTokenizer.from_pretrained('bert-base-uncased')\n                self.models['bert'] = BERTClass()\n                self.models['bert'].load_state_dict(torch.load(MODEL_PATHS['bert'], map_location=device))\n                self.models['bert'].to(device)\n                self.models['bert'].eval()\n                self.model_status['bert'] = True\n                logger.info(\"‚úì BERT model loaded successfully\")\n            else:\n                logger.warning(f\"‚úó BERT model file not found: {MODEL_PATHS['bert']}\")\n                self.model_status['bert'] = False\n        except Exception as e:\n            logger.error(f\"‚úó Failed to load BERT model: {str(e)}\")\n            self.model_status['bert'] = False\n        \n        # RoBERTa\n        try:\n            if os.path.exists(MODEL_PATHS['roberta']):\n                self.tokenizers['roberta'] = RobertaTokenizer.from_pretrained('roberta-base')\n                self.models['roberta'] = RoBERTaClass()\n                self.models['roberta'].load_state_dict(torch.load(MODEL_PATHS['roberta'], map_location=device))\n                self.models['roberta'].to(device)\n                self.models['roberta'].eval()\n                self.model_status['roberta'] = True\n                logger.info(\"‚úì RoBERTa model loaded successfully\")\n            else:\n                logger.warning(f\"‚úó RoBERTa model file not found: {MODEL_PATHS['roberta']}\")\n                self.model_status['roberta'] = False\n        except Exception as e:\n            logger.error(f\"‚úó Failed to load RoBERTa model: {str(e)}\")\n            self.model_status['roberta'] = False\n        \n        # Check if at least one model loaded\n        if not any(self.model_status.values()):\n            raise RuntimeError(\"No models could be loaded. Please check model files and paths.\")\n        \n        active_models = [name for name, status in self.model_status.items() if status]\n        logger.info(f\"Ensemble initialized with {len(active_models)} models: {', '.join(active_models)}\")\n    \n    def _infer_single_model(self, text: str, model_name: str) -> Optional[Tuple[np.ndarray, np.ndarray]]:\n        \"\"\"Run inference on a single model with error handling\"\"\"\n        \n        if not self.model_status.get(model_name, False):\n            return None\n        \n        try:\n            tokenizer = self.tokenizers[model_name]\n            model = self.models[model_name]\n            \n            # Tokenize input\n            encoded = tokenizer.encode_plus(\n                text,\n                max_length=MAX_LEN,\n                padding='max_length',\n                truncation=True,\n                return_attention_mask=True,\n                return_tensors='pt'\n            )\n            \n            input_ids = encoded['input_ids'].to(device)\n            attention_mask = encoded['attention_mask'].to(device)\n            \n            # Run inference\n            with torch.no_grad():\n                logits = model(input_ids, attention_mask)\n                probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n            \n            # Handle single dimension case\n            if probs.ndim == 0:\n                probs = np.array([probs])\n            \n            binary_preds = (probs >= 0.5).astype(int)\n            return probs, binary_preds\n            \n        except Exception as e:\n            logger.error(f\"Error during {model_name} inference: {str(e)}\")\n            return None\n    \n    def predict(self, text: str, combination_method: str = 'average') -> Dict:\n        \"\"\"\n        Run ensemble prediction with multiple combination strategies\n        \n        Args:\n            text: Input text to classify\n            combination_method: 'average', 'majority_vote', or 'weighted'\n        \n        Returns:\n            Dictionary with combined results and individual model results\n        \"\"\"\n        \n        if not text or not text.strip():\n            raise ValueError(\"Input text cannot be empty\")\n        \n        results = {\n            'input_text': text,\n            'individual_results': {},\n            'ensemble_result': {},\n            'model_status': self.model_status.copy(),\n            'combination_method': combination_method\n        }\n        \n        all_probs = []\n        all_preds = []\n        successful_models = []\n        \n        # Get predictions from each model\n        for model_name in ['distilbert', 'bert', 'roberta']:\n            model_result = self._infer_single_model(text, model_name)\n            \n            if model_result is not None:\n                probs, preds = model_result\n                results['individual_results'][model_name] = {\n                    'probabilities': probs,\n                    'predictions': preds,\n                    'detected_aspects': [target_list[i] for i, p in enumerate(preds) if p == 1]\n                }\n                all_probs.append(probs)\n                all_preds.append(preds)\n                successful_models.append(model_name)\n            else:\n                results['individual_results'][model_name] = {'error': 'Model failed or not available'}\n        \n        if not successful_models:\n            raise RuntimeError(\"All models failed to produce predictions\")\n        \n        # Combine predictions\n        all_probs = np.array(all_probs)\n        all_preds = np.array(all_preds)\n        \n        if combination_method == 'average':\n            ensemble_probs = np.mean(all_probs, axis=0)\n            ensemble_preds = (ensemble_probs >= 0.5).astype(int)\n        \n        elif combination_method == 'majority_vote':\n            ensemble_preds = (np.sum(all_preds, axis=0) >= len(successful_models) / 2).astype(int)\n            ensemble_probs = np.mean(all_probs, axis=0)  # Still provide probabilities\n        \n        elif combination_method == 'weighted':\n            # Weight models based on assumed performance (you can adjust these weights)\n            weights = {'distilbert': 0.8, 'bert': 1.0, 'roberta': 1.2}\n            model_weights = [weights.get(name, 1.0) for name in successful_models]\n            model_weights = np.array(model_weights) / sum(model_weights)  # Normalize\n            \n            ensemble_probs = np.average(all_probs, axis=0, weights=model_weights)\n            ensemble_preds = (ensemble_probs >= 0.5).astype(int)\n        \n        else:\n            raise ValueError(f\"Unknown combination method: {combination_method}\")\n        \n        # Store ensemble results\n        results['ensemble_result'] = {\n            'probabilities': ensemble_probs,\n            'predictions': ensemble_preds,\n            'detected_aspects': [target_list[i] for i, p in enumerate(ensemble_preds) if p == 1],\n            'successful_models': successful_models,\n            'num_models_used': len(successful_models)\n        }\n        \n        return results\n    \n    def print_results(self, results: Dict):\n        \"\"\"Pretty print the ensemble results\"\"\"\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"ENSEMBLE ASPECT CLASSIFICATION RESULTS\")\n        print(f\"{'='*60}\")\n        print(f\"Input: {results['input_text']}\")\n        print(f\"Combination Method: {results['combination_method'].upper()}\")\n        print(f\"Models Used: {', '.join(results['ensemble_result']['successful_models'])}\")\n        print(f\"Total Models: {results['ensemble_result']['num_models_used']}\")\n        \n        # Ensemble Results\n        print(f\"\\nüéØ ENSEMBLE PREDICTIONS:\")\n        ensemble = results['ensemble_result']\n        detected = ensemble['detected_aspects']\n        \n        if detected:\n            print(\"Detected Aspects:\")\n            for i, pred in enumerate(ensemble['predictions']):\n                if pred == 1:\n                    prob = ensemble['probabilities'][i] * 100\n                    print(f\"  ‚úì {target_list[i]}: {prob:.2f}%\")\n        else:\n            print(\"  No aspects detected above threshold\")\n        \n        print(f\"\\nFull Ensemble Probabilities:\")\n        sorted_results = sorted(zip(target_list, ensemble['probabilities']), \n                              key=lambda x: x[1], reverse=True)\n        for aspect, prob in sorted_results:\n            print(f\"  {aspect}: {prob*100:.2f}%\")\n        \n        # Individual Model Results\n        print(f\"\\nüìä INDIVIDUAL MODEL RESULTS:\")\n        for model_name, result in results['individual_results'].items():\n            if 'error' in result:\n                print(f\"\\n{model_name.upper()}: ‚ùå {result['error']}\")\n            else:\n                print(f\"\\n{model_name.upper()}:\")\n                detected = result['detected_aspects']\n                if detected:\n                    print(f\"  Detected: {', '.join(detected)}\")\n                else:\n                    print(f\"  Detected: None\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:40:59.014699Z","iopub.execute_input":"2025-05-22T02:40:59.015307Z","iopub.status.idle":"2025-05-22T02:40:59.042340Z","shell.execute_reply.started":"2025-05-22T02:40:59.015285Z","shell.execute_reply":"2025-05-22T02:40:59.041662Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"\n# Usage Example\ndef main():\n    try:\n        # Initialize ensemble\n        ensemble = AspectEnsemble()\n        \n        # Test text\n        raw_text = \"The phone runs well for basic tasks, but it gets warm during gaming. The screen is okay, and the battery lasts a day. Not bad, not great.\"\n        \n        # Run prediction with single method (you can change this to 'majority_vote' or 'weighted')\n        try:\n            results = ensemble.predict(raw_text, combination_method='average')\n            ensemble.print_results(results)\n        except Exception as e:\n            logger.error(f\"Error during prediction: {str(e)}\")\n        \n    except Exception as e:\n        logger.error(f\"Failed to initialize ensemble: {str(e)}\")\n        print(\"Please check that at least one model file exists and is valid.\")\n\n# Simple prediction function for easy use\ndef predict_aspects(text, method='average'):\n    \"\"\"\n    Simple function to get aspect predictions\n    \n    Args:\n        text: Input text to analyze\n        method: Combination method ('average', 'majority_vote', 'weighted')\n    \n    Returns:\n        Dictionary with results\n    \"\"\"\n    try:\n        ensemble = AspectEnsemble()\n        return ensemble.predict(text, combination_method=method)\n    except Exception as e:\n        logger.error(f\"Prediction failed: {str(e)}\")\n        return None\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:43:11.477524Z","iopub.execute_input":"2025-05-22T02:43:11.477809Z","iopub.status.idle":"2025-05-22T02:43:15.415357Z","shell.execute_reply.started":"2025-05-22T02:43:11.477790Z","shell.execute_reply":"2025-05-22T02:43:15.414616Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nENSEMBLE ASPECT CLASSIFICATION RESULTS\n============================================================\nInput: The phone runs well for basic tasks, but it gets warm during gaming. The screen is okay, and the battery lasts a day. Not bad, not great.\nCombination Method: AVERAGE\nModels Used: distilbert, bert, roberta\nTotal Models: 3\n\nüéØ ENSEMBLE PREDICTIONS:\nDetected Aspects:\n  ‚úì BATTERY: 96.89%\n  ‚úì PERFORMANCE: 96.71%\n  ‚úì DISPLAY: 73.49%\n\nFull Ensemble Probabilities:\n  BATTERY: 96.89%\n  PERFORMANCE: 96.71%\n  DISPLAY: 73.49%\n  CUSTOMIZATION: 9.21%\n  CAMERA: 7.98%\n  MULTIMEDIA: 6.72%\n  FITNESS & HEALTH TRACKING: 3.63%\n  PRICE: 1.85%\n\nüìä INDIVIDUAL MODEL RESULTS:\n\nDISTILBERT:\n  Detected: BATTERY, PERFORMANCE, DISPLAY\n\nBERT:\n  Detected: BATTERY, PERFORMANCE, DISPLAY\n\nROBERTA:\n  Detected: BATTERY, PERFORMANCE, DISPLAY\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}